# -*- coding: utf-8 -*-
"""Proyek_1_Machine_Learning_Terapan_Predictive_Analytics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iRKKUPACxLSOxeP0c6oeFFUoShgXCBvP

Nama : Nimas Ristiya Rahma

Program : Bangkit Academy 2024

# Predictive Analytics - Prediksi Penghasilan Karyawan Berdasarkan Lama Pengalaman Bekerja

# Deskripsi Proyek

Topik proyek ini berfokus pada analisis ekonomi dan bisnis, khususnya dalam konteks perekrutan karyawan baru. Perusahaan ingin mengetahui kisaran gaji yang sesuai berdasarkan lama pengalaman kerja para calon pelamar. Untuk mencapai tujuan ini, dua model Machine Learning akan diterapkan, dan model yang memberikan prediksi paling akurat akan dipilih.

# Tahap 1: Installasi dan Persiapan Library
Pada tahap ini, saya menginstal dan mengimpor beberapa library yang dibutuhkan untuk menjalankan proses analisis, pemrosesan data, serta visualisasi. Library seperti numpy, pandas, matplotlib, dan seaborn digunakan untuk manipulasi data dan visualisasi, sementara scikit-learn menyediakan alat untuk pemodelan Machine Learning.
"""

# Install public API Kaggle
!pip install -q kaggle

# Commented out IPython magic to ensure Python compatibility.
# Install library untuk proses data loading dan visualisasi data
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns

# Impor library untuk data preparation
from sklearn.preprocessing import StandardScaler

# Impor library untuk split data
from sklearn.model_selection import train_test_split

# Impor metrik
from sklearn.metrics import mean_squared_error

# Impor model
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression

"""# 2. Data Understanding
Pemahaman data adalah langkah pertama dalam setiap proyek analisis data. Pada tahap ini, kita akan memeriksa dan memahami informasi yang terkandung dalam dataset untuk menilai kualitas data tersebut. Proses ini penting untuk memastikan bahwa data yang digunakan memiliki kualitas yang baik dan siap untuk dianalisis lebih lanjut.

Dataset : https://www.kaggle.com/datasets/rubydoby/years-of-experience-and-employees-salary

# 2.1 Data Loading
Pemrosesan data adalah langkah untuk memuat dataset yang akan digunakan dalam analisis. Di tahap ini, kita akan mengunduh dataset dari Kaggle, mengekstraknya, dan memuatnya ke dalam format yang lebih mudah untuk dianalisis dengan menggunakan Python.

Dataset yang digunakan dalam proyek ini adalah Years of Experience and Employee's Salary yang dapat diakses melalui Kaggle, yang berisi data pengalaman kerja karyawan dan gaji mereka.
"""

# Membuat direktori baru bernama kaggle
!rm -rf ~/.kaggle && mkdir ~/.kaggle/

# Menyalin berkas kaggle.json pada direktori aktif saat ini ke direktori kaggle
!mv kaggle.json ~/.kaggle/kaggle.json

# Mengubah permission berkas
!chmod 600 ~/.kaggle/kaggle.json

# Download dataset
!kaggle datasets download -d rubydoby/years-of-experience-and-employees-salary

# Ekstrak berkas zip
!unzip /content/years-of-experience-and-employees-salary.zip

# Melihat isi dataset
salary = pd.read_csv('/content/employee_salaries.csv')
salary

"""Hasil Dataset
Dataset yang diunduh memiliki dua kolom utama, yaitu:

Years of Experience: Mengindikasikan jumlah tahun pengalaman kerja seorang karyawan.
Salary: Gaji tahunan karyawan dalam satuan dolar.

Dataset ini memiliki 1500 baris dan 2 kolom, yang mencerminkan hubungan antara pengalaman kerja dan gaji karyawan.

# 2.2 Exploratory Data Analysis (EDA)
Analisis Data Eksploratif (EDA) adalah langkah awal dalam memeriksa data untuk menganalisis karakteristiknya, mengidentifikasi pola, mendeteksi anomali, dan memverifikasi asumsi yang ada. Teknik ini biasanya melibatkan penggunaan statistik deskriptif serta representasi grafis atau visualisasi untuk memberikan wawasan lebih lanjut tentang struktur dan kualitas data.

# 2.2.1 EDA - Deskripsi Variabel
Pada tahap ini, kita akan melihat informasi tentang variabel yang ada dalam dataset. Dengan memeriksa tipe data dan statistik deskriptif, kita dapat memperoleh gambaran umum mengenai distribusi dan rentang data.
"""

# Melihat informasi pada dataset
salary.info()

"""Dataset ini memiliki 1500 entri dan terdiri dari 2 kolom yaitu Years of Experience dan Salary, keduanya bertipe data float64.

Selanjutnya, kita akan melihat statistik deskriptif dari dataset untuk mendapatkan pemahaman lebih lanjut tentang nilai-nilai utama seperti rata-rata, median, dan sebaran data.
"""

# Mengecek deskripsi statistik data
salary.describe()

"""Dari statistik di atas, kita dapat melihat bahwa rata-rata pengalaman kerja karyawan dalam dataset adalah sekitar 10.79 tahun, dan gaji rata-rata karyawan adalah sekitar 112,627. Rentang gaji antara 40,000 hingga 500,000 menunjukkan adanya variasi gaji yang cukup besar.

# 2.2.2 EDA - Menangani Missing Value dan Outliers
**1. Memeriksa Missing Value**

Langkah pertama adalah memastikan bahwa tidak ada data yang hilang (missing values) pada dataset.
"""

# Mengecek dataset jika ada yang kosong
salary.isna().sum()

"""Tidak ada nilai yang hilang pada dataset, sehingga tidak perlu dilakukan penanganan lebih lanjut terhadap missing values.

**2. Menangani Outliers**
Outliers adalah nilai yang jauh berbeda dari mayoritas data, yang bisa mempengaruhi hasil analisis dan model. Untuk mendeteksi outliers, kita dapat menggunakan visualisasi seperti boxplot.
"""

# Menghapus baris data jika ada yang kosong
salary = salary.dropna(axis=0)
salary.shape

"""Boxplot akan membantu untuk mengidentifikasi apakah terdapat data yang sangat jauh dari distribusi mayoritas. Jika ditemukan outliers yang signifikan, kita bisa mempertimbangkan untuk menangani atau menghapusnya, tergantung pada analisis lebih lanjut."""

# Visualisasi pada fitur untuk melihat outliers
sns.boxplot(x=salary['Years of Experience'])

"""Saya menggunakan boxplot untuk memvisualisasikan distribusi data gaji. Boxplot ini menampilkan rentang data, kuartil, serta potensi outliers. Sumbu x menunjukkan variabel "Salary" dalam dataset."""

# Visualisasi pada fitur untuk melihat outliers
sns.boxplot(x=salary['Salary'])

"""Di sini, saya menghitung kuartil pertama (Q1) dan kuartil ketiga (Q3) dari kolom "Salary". Selanjutnya, saya menghitung Interquartile Range (IQR), yang merupakan selisih antara Q3 dan Q1. IQR digunakan untuk mendeteksi outliers.

Saya menyaring data untuk menghilangkan nilai-nilai yang berada di luar rentang outlier yang ditentukan. Rentang yang aman adalah antara
ùëÑ
1
‚àí
1.5
√ó
ùêº
ùëÑ
ùëÖ
Q1‚àí1.5√óIQR dan
ùëÑ
3
+
1.5
√ó
ùêº
ùëÑ
ùëÖ
Q3+1.5√óIQR. Baris yang memiliki nilai di luar rentang ini akan dihapus dari dataset.
"""

# Menangani outliers dengan IQR method
Q1 = salary.quantile(0.25)
Q3 = salary.quantile(0.75)
IQR=Q3-Q1
salary=salary[~((salary<(Q1-1.5*IQR))|(salary>(Q3+1.5*IQR))).any(axis=1)]

# Cek ukuran dataset setelah outliers di drop
salary.shape

"""Dengan kode ini, saya memeriksa ukuran dataset setelah outliers dihapus. Hasil (1338, 2) menunjukkan bahwa dataset memiliki 1338 baris dan 2 kolom setelah pembersihan.

# 2.2.3 EDA - Univariate Analysis
**1. Visualisasi Histogram untuk Fitur Numerik**

Saya menggunakan fungsi hist() untuk memvisualisasikan distribusi fitur numerik dalam dataset, dalam hal ini adalah kolom "Salary". Dengan memilih 50 bin, saya membagi rentang data menjadi interval yang lebih kecil untuk melihat distribusi data secara lebih detail. Ukuran grafik diatur menjadi besar (20x15) agar lebih jelas.
"""

# Visualisasi fitur numerik untuk melihat masing-masing histogram
salary.hist(bins=50, figsize=(20,15))
plt.show()

"""# 2.2.4 EDA - Multivariate Analysis
**2. Mengamati Hubungan Antar Fitur dengan Pairplot**

Saya menggunakan fungsi pairplot() untuk memvisualisasikan hubungan antar fitur dalam dataset. Fungsi ini membuat pasangan plot untuk setiap kombinasi fitur numerik, sehingga saya bisa melihat pola atau korelasi antara dua fitur sekaligus. Diagonal plot akan menggunakan kernel density estimate (KDE) untuk menunjukkan distribusi setiap fitur.
"""

# Mengamati hubungan antar fitur dengan fungsi pairplot()
sns.pairplot(salary, diag_kind = 'kde')

"""**3. Mengamati Korelasi Antar Fitur dengan Heatmap**

Saya menghitung matriks korelasi antara fitur-fitur numerik dalam dataset menggunakan metode .corr(). Hasilnya adalah matriks yang menunjukkan seberapa besar hubungan antara satu fitur dengan fitur lainnya. Kemudian, saya memvisualisasikan matriks korelasi ini menggunakan heatmap untuk melihat pola korelasi dengan lebih jelas. Warna pada heatmap menggambarkan kekuatan korelasi, sementara angka yang ditampilkan (annot=True) menunjukkan nilai korelasi. Saya menggunakan skema warna coolwarm dan memberi sedikit jarak antar baris kolom dengan linewidths=0.5. Grafik ini berguna untuk memahami hubungan antar fitur secara keseluruhan.
"""

# Mengamati korelasi antar fitur dengan menggunakan heatmap
plt.figure(figsize=(10, 8))
correlation_matrix = salary.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True, cmap='coolwarm', linewidths=0.5, )
plt.title("Matriks Korelasi untuk Fitur Numerik ", size=20)

"""# 3. Data Preparation

**3.1 Train-Test-Split**

Membagi Dataset menjadi Data Latih dan Data Uji
"""

# Membagi dataset menjadi data latih dan data uji, kali ini proporsi pembagiannya adalah 90:10
X = salary.drop(["Salary"],axis =1)
y = salary["Salary"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 123)

"""Di sini, saya memisahkan dataset menjadi dua bagian:

*   X berisi fitur (kolom selain "Salary"), dan
*   y berisi target (kolom "Salary").

Kemudian, saya menggunakan train_test_split dari Scikit-Learn untuk membagi data menjadi data latih (X_train, y_train) dan data uji (X_test, y_test). Proporsi pembagian adalah 90% untuk data latih dan 10% untuk data uji, yang ditentukan dengan test_size=0.1. random_state=123 memastikan pembagian yang konsisten setiap kali kode dijalankan.

Mencetak Ukuran Dataset
"""

print(f'Total seluruh sampel dalam dataset: {len(X)}')
print(f'Total sampel dalam train dataset: {len(X_train)}')
print(f'Total samepl dalam test dataset: {len(X_test)}')

"""Saya mencetak jumlah sampel dalam keseluruhan dataset, serta jumlah sampel dalam dataset latih dan uji. Hasil yang ditampilkan menunjukkan bahwa total sampel dalam dataset adalah 1338, dengan 1204 sampel digunakan untuk data latih dan 134 sampel untuk data uji.

# 3.2 Standarisasi
Proses Standarisasi Data Latih Menggunakan StandardScaler
"""

# Melakukan proses standarisasi pada data latih menggunakan StandardScaler
numerical_features = ['Years of Experience']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

"""Saya menggunakan StandardScaler untuk menstandarisasi data latih. Standarisasi dilakukan untuk memastikan fitur "Years of Experience" memiliki distribusi dengan rata-rata 0 dan standar deviasi 1. Proses ini penting untuk meningkatkan kinerja model machine learning, terutama jika model yang digunakan sensitif terhadap skala data (misalnya, model berbasis jarak seperti KNN atau SVM).

*   scaler.fit(X_train[numerical_features]): Saya melatih scaler pada data latih untuk menghitung rata-rata dan standar deviasi dari fitur "Years of Experience".
*   X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features]): Setelah scaler dilatih, saya menerapkannya untuk mentransformasikan data latih, sehingga nilai pada kolom "Years of Experience" distandarisasi.

Melihat Statistik Data yang Sudah Distandarisasi
"""

# Melihat statistik data yang sudah di standarisasi
X_train[numerical_features].describe().round(4)

"""Saya mencetak statistik deskriptif dari fitur "Years of Experience" setelah distandarisasi. Hasilnya menunjukkan:

*   Rata-rata (mean) = 0 dan standar deviasi (std) sekitar 1, sesuai dengan tujuan standarisasi.
*   Nilai minimum dan maksimum yang lebih kecil atau lebih besar dari rata-rata menunjukkan sebaran data setelah standarisasi.

# 4.1 Mempersiapkan DataFrame untuk Analisis Model
Mempersiapkan DataFrame untuk Menyimpan Hasil Evaluasi Mode
"""

models = pd.DataFrame(index=['train_mse', 'test_mse'],
                      columns=['LinearRegression'])

"""Di sini, saya membuat sebuah DataFrame kosong bernama models yang memiliki indeks train_mse dan test_mse, yang nantinya akan digunakan untuk menyimpan nilai Mean Squared Error (MSE) dari model yang diuji. Kolom pada DataFrame ini berisi nama model yang diterapkan, dalam hal ini adalah LinearRegression. DataFrame ini berguna untuk memantau kinerja model pada data latih dan data uji.

# 4.2 Membuat Model dengan Algoritma Linear Regression
Membuat dan Melatih Model Linear Regression, Menghitung dan Menyimpan MSE untuk Data Latih

Di sini, saya membuat model regresi linier menggunakan LinearRegression dari Scikit-Learn. Parameter n_jobs = -1 digunakan untuk mempercepat proses pelatihan model dengan memanfaatkan semua inti prosesor yang tersedia. Saya kemudian melatih model menggunakan data latih X_train dan target y_train.
"""

LR = LinearRegression(n_jobs = -1)
LR.fit(X_train,y_train)
models.loc['train_mse','LR'] = mean_squared_error(y_pred=LR.predict(X_train), y_true=y_train)

"""Setelah model dilatih, saya menghitung Mean Squared Error (MSE) pada data latih menggunakan fungsi mean_squared_error dari Scikit-Learn. Fungsi ini membandingkan prediksi yang dihasilkan model (LR.predict(X_train)) dengan nilai target sesungguhnya (y_train). Nilai MSE ini menunjukkan seberapa besar kesalahan prediksi pada data latih. Hasilnya disimpan dalam DataFrame models pada baris train_mse dan kolom LR.

# 5. Evaluasi Model
Standarisasi pada Fitur Numerik di Data Uji

Sebelum melakukan evaluasi model pada data uji (X_test), saya melakukan standarisasi pada fitur numerik yang ada di dalam data uji menggunakan scaler.transform(). Proses ini penting karena model telah dilatih dengan data latih yang sudah distandarisasi, sehingga data uji juga harus distandarisasi dengan cara yang sama agar prediksi model dapat akurat.
"""

# Melakukan standarisasi terhadap fitur numerik pada data uji
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

"""# 5.1 Evaluasi Model Menggunakan Metrik MSE
Membuat DataFrame untuk Menyimpan Nilai MSE

Saya membuat DataFrame mse yang akan menyimpan nilai Mean Squared Error (MSE) untuk data latih dan data uji. Baris pada DataFrame ini berisi nama model (LinearRegression), dan kolom berisi nilai MSE untuk data latih dan uji.

Saya melakukan perulangan untuk menghitung MSE pada data latih (X_train) dan data uji (X_test). Fungsi mean_squared_error membandingkan prediksi (model.predict(X_train) dan model.predict(X_test)) dengan nilai sesungguhnya (y_train dan y_test). Hasil MSE dibagi dengan
1
√ó
1
0
3
1√ó10
3
  agar nilai yang ditampilkan lebih mudah dibaca. Nilai MSE ini kemudian disimpan dalam DataFrame mse.

Outputnya menunjukkan nilai MSE untuk data latih dan data uji pada model regresi linier:

MSE untuk data latih: 113,458.1
MSE untuk data uji: 127,004.9
"""

# Membuat variabel mse yang berisi dataframe dari nilai mse data latih dan data uji pada model
mse = pd.DataFrame(columns=['train', 'test'], index=['LinearRegression'])

# Membuat dictionary untuk algoritma model yang digunakan
model_dict = {'LinearRegression': LR}

# Menghitung Mean Squared Error algoritma pada data latih dan data uji
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# memanggil mse
mse

"""Saya membuat plot horizontal menggunakan plot(kind='barh') untuk menampilkan nilai MSE model pada data latih dan data uji. Plot ini akan memudahkan untuk membandingkan kinerja model pada kedua set data. zorder digunakan untuk mengatur urutan elemen plot, dengan grid berada di bawah grafik untuk meningkatkan visibilitas."""

# Visualisasi plot metrik
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""5.2 Melakukan Pengujian

Di sini, saya melakukan pengujian terhadap model pada sampel data uji yang dipilih (baris ke-2 sampai ke-3 dari X_test). Saya membuat dictionary pred_dict yang berisi nilai sesungguhnya (y_true) dari target data uji tersebut, serta prediksi dari model (prediksi_LinearRegression). Nilai prediksi model kemudian dibulatkan menjadi satu angka desimal.

Menampilkan Hasil Pengujian Model: Output yang dihasilkan menunjukkan perbandingan antara nilai sesungguhnya (y_true) dan prediksi model:

Nilai sesungguhnya (y_true) untuk sampel tersebut adalah 87,000.
Prediksi dari model regresi linier adalah 81,493.4.
"""

# Melakukan pengujian terhadap model
prediksi = X_test.iloc[2:3].copy()
pred_dict = {'y_true':y_test[2:3]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""**6. Improvement**

Karena hasil prediksi menggunakan algoritma Linear Regression belum cukup akurat dibandingkan dengan nilai sebenarnya, kita akan membandingkannya dengan algoritma lain, yaitu Random Forest.

6.1 Membuat Model dengan Algoritma Random Forest
"""

# Membuat model prediksi menggunakan algoritma Random Forest
RF = RandomForestRegressor(n_estimators=50, max_depth=16, random_state=55, n_jobs=-1)
RF.fit(X_train, y_train)

models.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RF.predict(X_train), y_true=y_train)

"""Di sini, saya membuat model Random Forest Regressor menggunakan RandomForestRegressor dari Scikit-Learn dengan parameter berikut:

*   n_estimators=50: Menggunakan 50 pohon keputusan dalam model Random Forest.
*   max_depth=16: Membatasi kedalaman maksimum pohon keputusan untuk menghindari overfitting.

*   random_state=55: Menetapkan nilai acak untuk reprodusibilitas hasil.
*   n_jobs=-1: Memanfaatkan semua inti prosesor yang tersedia untuk mempercepat proses pelatihan.

Setelah model dilatih pada data latih (X_train, y_train), saya menghitung Mean Squared Error (MSE) untuk data latih dan menyimpannya dalam DataFrame models di baris train_mse pada kolom RandomForest.

6.2 Membandingkan Hasil Evaluasi dari Kedua Model Menggunakan Metrik MSE
"""

# Membuat variabel mse yang berisi dataframe dari nilai mse data latih dan data uji pada model
mse = pd.DataFrame(columns=['train', 'test'], index=['LinearRegression', 'RandomForest'])

# Membuat dictionary untuk algoritma model yang digunakan
model_dict = {'LinearRegression': LR, 'RandomForest': RF}

# Menghitung Mean Squared Error algoritma pada data latih dan data uji
for name, model in model_dict.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))/1e3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))/1e3

# Memanggil mse untuk membandingkan model
mse

# Visualisasi plot metrik
fig, ax = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=ax, zorder=3)
ax.grid(zorder=0)

"""6.2 Melakukan Pengujian dari Kedua Model"""

# Melakukan pengujian terhadap model
prediksi = X_test.iloc[2:3].copy()
pred_dict = {'y_true':y_test[2:3]}
for name, model in model_dict.items():
    pred_dict['prediksi_'+name] = model.predict(prediksi).round(1)

pd.DataFrame(pred_dict)

"""Saya memilih satu sampel data uji untuk diuji pada kedua model. Prediksi dari kedua model (regresi linier dan Random Forest) dibandingkan dengan nilai sesungguhnya (y_true). Hasil prediksi untuk kedua model adalah:

Nilai sesungguhnya (y_true) untuk sampel tersebut: 87,000.
Prediksi oleh Linear Regression: 81,493.4
Prediksi oleh Random Forest: 87,768.2
Berdasarkan hasil ini, model Random Forest memberikan prediksi yang lebih mendekati nilai sesungguhnya dibandingkan dengan model regresi linier.
"""

